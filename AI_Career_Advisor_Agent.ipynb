{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sankeerth55/AI-Career-Advisor-Agent/blob/main/AI_Career_Advisor_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzSbErsaPAxJ",
        "outputId": "03f7049a-4be3-47c5-bbd0-bfb594168946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.30.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.10.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.11.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "apcljDdUP_B6"
      },
      "outputs": [],
      "source": [
        "!pip install -q U langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "sb3x2hikQCkq",
        "outputId": "34f98762-5fff-4aec-c653-5785eea9131c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.11/dist-packages (2.1.9)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain_google_genai)\n",
            "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.3.74)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.3.1)\n",
            "Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ddfea642854f42b9b4605f0167b23e6e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkXdSUXJQEnK",
        "outputId": "fcdaccf8-00ab-4091-d924-c1ac52d1d6a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.11/dist-packages (0.7.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.11.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2025.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (4.14.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "J9IcWrF9QGqP"
      },
      "outputs": [],
      "source": [
        "!pip install -q U langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "sK10QUGmRmXJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "wYxgjKgqR265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8b6f14-7c16-4649-9277-fb5b7ad746e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of Karnataka is **Bangalore**.\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",api_key=API_KEY)\n",
        "response = model.invoke(\"What is the capital of karnataka?\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "EE6EvecPSwfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99654939-7b96-4afe-fdff-e37d0c93d8da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-312507512.py:38: LangGraphDeprecatedSinceV10: MessageGraph is deprecated in LangGraph v1.0.0, to be removed in v2.0.0. Please use StateGraph with a `messages` key instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  graph = MessageGraph()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN:\n",
            "\n",
            "    Candidate Resume:\n",
            "    Education: Bachelor of Technology in Computer Science\n",
            "    Skills: Python, LangChain, SQL\n",
            "    Experience: Internship at an AI-based startup\n",
            "    \n",
            "\n",
            "HUMAN:\n",
            "My goal is to become a Data Scientist within the next year.\n",
            "\n",
            "AI:\n",
            "Okay, I can extract the requested sections from the provided resume.\n",
            "\n",
            "**1. Skills:**\n",
            "\n",
            "*   (None listed)\n",
            "\n",
            "**2. Education:**\n",
            "\n",
            "*   (None listed)\n",
            "\n",
            "**3. Experience:**\n",
            "\n",
            "*   (None listed)\n",
            "\n",
            "AI:\n",
            "Okay, given your profile (goal: Data Scientist in 12 months, and no existing skills, education, or experience listed), this is a realistic and ambitious 12-month roadmap. It assumes you are starting from scratch and willing to dedicate significant time and effort.  It focuses on building a solid foundation and demonstrating practical skills.  This roadmap prioritizes a blend of theoretical knowledge, hands-on projects, and networking.\n",
            "\n",
            "**Phase 1: Foundations (Months 1-3): Building a Base**\n",
            "\n",
            "*   **Month 1: Math & Statistics Fundamentals:**\n",
            "    *   **Goal:** Develop a strong understanding of core mathematical and statistical concepts essential for data science.\n",
            "    *   **Activities:**\n",
            "        *   **Mathematics:**\n",
            "            *   Linear Algebra: Vectors, matrices, matrix operations, eigenvalues, eigenvectors (Khan Academy, MIT OpenCourseware).  Aim for basic proficiency.\n",
            "            *   Calculus: Derivatives, integrals, optimization (Khan Academy, MIT OpenCourseware).  Focus on understanding how these are used in machine learning (e.g., gradient descent).\n",
            "        *   **Statistics:**\n",
            "            *   Descriptive Statistics: Mean, median, mode, standard deviation, variance, distributions (normal, binomial, Poisson).\n",
            "            *   Inferential Statistics: Hypothesis testing, confidence intervals, p-values, t-tests, ANOVA.\n",
            "            *   Probability: Basic probability rules, conditional probability, Bayes' Theorem.\n",
            "        *   **Resources:**\n",
            "            *   Khan Academy (Mathematics & Statistics)\n",
            "            *   MIT OpenCourseware (Mathematics & Statistics)\n",
            "            *   \"OpenIntro Statistics\" (Free online textbook)\n",
            "    *   **Deliverables:**\n",
            "        *   Complete basic courses on linear algebra, calculus, and statistics.\n",
            "        *   Be able to explain key statistical concepts in your own words.\n",
            "\n",
            "*   **Month 2: Programming (Python) & Data Handling:**\n",
            "    *   **Goal:** Learn Python and essential data manipulation libraries.\n",
            "    *   **Activities:**\n",
            "        *   **Python:**\n",
            "            *   Basic syntax, data types, control flow, functions, object-oriented programming (OOP) fundamentals.\n",
            "            *   Learn to use Jupyter Notebooks (or Google Colab) for interactive coding.\n",
            "        *   **Data Handling Libraries:**\n",
            "            *   NumPy: Numerical computing, array manipulation.\n",
            "            *   Pandas: Data analysis, dataframes, data cleaning, data wrangling.\n",
            "        *   **Resources:**\n",
            "            *   Codecademy (Python)\n",
            "            *   DataCamp (Python, Pandas, NumPy)\n",
            "            *   \"Automate the Boring Stuff with Python\" (Free online book)\n",
            "    *   **Deliverables:**\n",
            "        *   Complete a Python fundamentals course.\n",
            "        *   Be able to load, clean, and manipulate data using Pandas.\n",
            "        *   Create simple scripts to perform basic data analysis tasks.\n",
            "\n",
            "*   **Month 3: Data Visualization & Databases:**\n",
            "    *   **Goal:** Master data visualization techniques and learn basic database concepts.\n",
            "    *   **Activities:**\n",
            "        *   **Data Visualization:**\n",
            "            *   Matplotlib: Basic plotting library for creating charts and graphs.\n",
            "            *   Seaborn: Higher-level plotting library for statistical visualizations.\n",
            "        *   **Databases:**\n",
            "            *   SQL: Learn to write basic SQL queries to retrieve and manipulate data from relational databases (e.g., MySQL, PostgreSQL).  Focus on SELECT, FROM, WHERE, JOIN, GROUP BY, ORDER BY.\n",
            "        *   **Resources:**\n",
            "            *   DataCamp (Data Visualization, SQL)\n",
            "            *   Mode Analytics SQL Tutorial\n",
            "            *   SQLZoo (Interactive SQL tutorial)\n",
            "    *   **Deliverables:**\n",
            "        *   Create various types of visualizations using Matplotlib and Seaborn (histograms, scatter plots, bar charts, etc.).\n",
            "        *   Be able to write SQL queries to extract specific data from a database.\n",
            "        *   Complete a small project involving data extraction, manipulation, visualization, and a brief written analysis.  (e.g., analyze a public dataset from Kaggle and create a simple dashboard).\n",
            "\n",
            "**Phase 2: Machine Learning Fundamentals (Months 4-7): Building Predictive Models**\n",
            "\n",
            "*   **Month 4: Supervised Learning - Regression:**\n",
            "    *   **Goal:** Understand and implement regression algorithms.\n",
            "    *   **Activities:**\n",
            "        *   Linear Regression: Simple and multiple linear regression.\n",
            "        *   Polynomial Regression\n",
            "        *   Regularization: Ridge and Lasso regression.\n",
            "        *   Model Evaluation: Mean Squared Error (MSE), R-squared.\n",
            "    *   **Resources:**\n",
            "        *   Andrew Ng's Machine Learning course on Coursera (focus on regression)\n",
            "        *   Scikit-learn documentation\n",
            "    *   **Deliverables:**\n",
            "        *   Implement linear regression from scratch (using NumPy).\n",
            "        *   Use Scikit-learn to train and evaluate regression models on different datasets.\n",
            "\n",
            "*   **Month 5: Supervised Learning - Classification:**\n",
            "    *   **Goal:** Understand and implement classification algorithms.\n",
            "    *   **Activities:**\n",
            "        *   Logistic Regression\n",
            "        *   K-Nearest Neighbors (KNN)\n",
            "        *   Decision Trees\n",
            "        *   Random Forests\n",
            "        *   Support Vector Machines (SVM)\n",
            "        *   Model Evaluation: Accuracy, Precision, Recall, F1-score, Confusion Matrix, ROC curves.\n",
            "    *   **Resources:**\n",
            "        *   Andrew Ng's Machine Learning course on Coursera (focus on classification)\n",
            "        *   Scikit-learn documentation\n",
            "    *   **Deliverables:**\n",
            "        *   Implement logistic regression from scratch (using NumPy).\n",
            "        *   Use Scikit-learn to train and evaluate classification models on different datasets.\n",
            "\n",
            "*   **Month 6: Unsupervised Learning & Model Selection:**\n",
            "    *   **Goal:** Learn unsupervised learning techniques and model selection strategies.\n",
            "    *   **Activities:**\n",
            "        *   **Unsupervised Learning:**\n",
            "            *   K-Means Clustering\n",
            "            *   Principal Component Analysis (PCA)\n",
            "        *   **Model Selection:**\n",
            "            *   Cross-validation (k-fold cross-validation)\n",
            "            *   Hyperparameter tuning (Grid Search, Random Search)\n",
            "    *   **Resources:**\n",
            "        *   Andrew Ng's Machine Learning course on Coursera (focus on unsupervised learning)\n",
            "        *   Scikit-learn documentation\n",
            "    *   **Deliverables:**\n",
            "        *   Implement K-Means clustering from scratch.\n",
            "        *   Use PCA for dimensionality reduction.\n",
            "        *   Apply cross-validation and hyperparameter tuning to improve model performance.\n",
            "\n",
            "*   **Month 7: Feature Engineering & Model Deployment (Basic):**\n",
            "    *   **Goal:** Learn how to prepare data for machine learning and deploy a simple model.\n",
            "    *   **Activities:**\n",
            "        *   **Feature Engineering:**\n",
            "            *   Handling missing values (imputation)\n",
            "            *   Encoding categorical variables (one-hot encoding, label encoding)\n",
            "            *   Feature scaling (standardization, normalization)\n",
            "            *   Creating new features from existing ones\n",
            "        *   **Basic Model Deployment:**\n",
            "            *   Learn about REST APIs using Flask or FastAPI (very basic introduction).\n",
            "            *   Deploy a simple model using a cloud platform like Heroku or AWS (free tier).\n",
            "    *   **Resources:**\n",
            "        *   Feature Engineering for Machine Learning (book)\n",
            "        *   Online tutorials on Flask/FastAPI and Heroku/AWS deployment.\n",
            "    *   **Deliverables:**\n",
            "        *   Preprocess data for machine learning using various feature engineering techniques.\n",
            "        *   Deploy a simple machine learning model as a REST API.\n",
            "\n",
            "**Phase 3: Specialization & Portfolio Building (Months 8-11): Demonstrating Expertise**\n",
            "\n",
            "*   **Month 8: Choose a Specialization:**\n",
            "    *   **Goal:** Identify a specific area of data science that interests you.\n",
            "    *   **Activities:**\n",
            "        *   Research different areas of data science (e.g., Natural Language Processing (NLP), Computer Vision, Time Series Analysis, Recommender Systems, Deep Learning).\n",
            "        *   Consider your interests and career goals.\n",
            "        *   Choose one specialization to focus on for the next few months.\n",
            "    *   **Deliverables:**\n",
            "        *   Clearly define your chosen specialization.\n",
            "\n",
            "*   **Months 9-10: Deep Dive into Specialization:**\n",
            "    *   **Goal:** Gain in-depth knowledge and practical experience in your chosen specialization.\n",
            "    *   **Activities:**\n",
            "        *   Take online courses or read books related to your specialization.\n",
            "        *   Work on projects that demonstrate your skills in your chosen area.  Focus on building at least 2-3 projects that showcase your abilities.  These projects should be more complex than the earlier ones.\n",
            "        *   Contribute to open-source projects (optional, but highly beneficial).\n",
            "    *   **Resources:**\n",
            "        *   Specialized online courses on Coursera, edX, Udacity, etc. (e.g., Deep Learning Specialization on Coursera if you choose Deep Learning)\n",
            "        *   Research papers and articles related to your specialization.\n",
            "        *   GitHub repositories for open-source projects in your area.\n",
            "    *   **Deliverables:**\n",
            "        *   Complete specialized courses.\n",
            "        *   Build a portfolio of projects that demonstrate your skills in your chosen specialization.\n",
            "        *   Contribute to open-source projects (optional).\n",
            "\n",
            "*   **Month 11: Portfolio Polishing & Networking:**\n",
            "    *   **Goal:** Refine your portfolio and build your professional network.\n",
            "    *   **Activities:**\n",
            "        *   **Portfolio Polishing:**\n",
            "            *   Ensure your projects are well-documented and easy to understand.\n",
            "            *   Write clear and concise descriptions of your projects.\n",
            "            *   Host your portfolio on GitHub Pages or a personal website.\n",
            "        *   **Networking:**\n",
            "            *   Attend data science meetups and conferences (online or in person).\n",
            "            *   Connect with data scientists on LinkedIn.\n",
            "            *   Participate in online data science communities (e.g., Kaggle forums, Reddit's r/datascience).\n",
            "            *   Practice your \"elevator pitch\" – a brief summary of your skills and experience.\n",
            "    *   **Deliverables:**\n",
            "        *   A polished and well-documented portfolio.\n",
            "        *   A professional LinkedIn profile.\n",
            "        *   A network of connections in the data science field.\n",
            "\n",
            "**Phase 4: Job Search & Interview Preparation (Month 12): Landing the Role**\n",
            "\n",
            "*   **Month 12: Job Applications & Interview Practice:**\n",
            "    *   **Goal:** Apply for data science jobs and prepare for interviews.\n",
            "    *   **Activities:**\n",
            "        *   **Job Search:**\n",
            "            *   Search for data science jobs on job boards (e.g., Indeed, LinkedIn, Glassdoor).\n",
            "            *   Tailor your resume and cover letter to each job application.\n",
            "        *   **Interview Preparation:**\n",
            "            *   Practice answering common data science interview questions (technical and behavioral).\n",
            "            *   Review your portfolio projects and be prepared to discuss them in detail.\n",
            "            *   Practice coding on a whiteboard or online coding platform (e.g., LeetCode).\n",
            "    *   **Resources:**\n",
            "        *   Cracking the Coding Interview (book)\n",
            "        *   Ace the Data Science Interview (book)\n",
            "        *   LeetCode (for coding practice)\n",
            "    *   **Deliverables:**\n",
            "        *   Apply for data science jobs.\n",
            "        *   Prepare for and ace data science interviews.\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "*   **Consistency is key:** Dedicate a specific amount of time each day or week to learning and practicing.\n",
            "*   **Hands-on practice is crucial:** Don't just read about concepts; implement them yourself.\n",
            "*   **Don't be afraid to ask for help:** Join online communities and ask questions when you get stuck.\n",
            "*   **Stay up-to-date:** The field of data science is constantly evolving, so keep learning and exploring new technologies.\n",
            "*   **Adaptability:** This is a roadmap, not a rigid plan. Be prepared to adjust your approach based on your progress and the opportunities that arise.\n",
            "*   **Realistic Expectations:**  Becoming a data scientist in 12 months with no prior experience is extremely challenging.  Be prepared for a lot of hard work and potential setbacks.  Focus on continuous improvement and learning.\n",
            "*   **Prioritization:**  If you have limited time, prioritize the core skills: Python, Pandas, Scikit-learn, Statistics, and Machine Learning fundamentals.\n",
            "\n",
            "This roadmap is a starting point. You'll need to customize it based on your individual needs and learning style. Good luck!\n",
            "\n",
            "AI:\n",
            "Okay, based on the 12-month roadmap and the assumption that you've diligently followed it, here are 3 suitable job roles to target and 3 open-source projects to consider contributing to, aligning with a junior or entry-level data scientist profile:\n",
            "\n",
            "**Suitable Job Roles (Targeting Junior/Entry-Level):**\n",
            "\n",
            "1.  **Junior Data Scientist / Data Analyst:** This is the most direct and realistic target. These roles typically involve:\n",
            "    *   Analyzing datasets to identify trends and insights.\n",
            "    *   Building and deploying basic machine learning models (e.g., regression, classification).\n",
            "    *   Creating data visualizations and reports.\n",
            "    *   Supporting senior data scientists with more complex projects.\n",
            "    *   **Why it's suitable:** It aligns with the foundational skills you've acquired in the roadmap (Python, Pandas, Scikit-learn, visualization, basic ML).  The \"Junior\" title indicates they expect someone with less experience.  \"Data Analyst\" roles often provide a pathway into Data Science as you gain experience.\n",
            "\n",
            "2.  **Machine Learning Engineer (Entry-Level / Associate):** While this role often requires a stronger software engineering background, some entry-level positions are accessible with a solid understanding of machine learning algorithms and model deployment. You'd likely be:\n",
            "    *   Assisting in the development and deployment of machine learning models in production.\n",
            "    *   Working with data pipelines and infrastructure.\n",
            "    *   Optimizing model performance and scalability.\n",
            "    *   Collaborating with software engineers and data scientists.\n",
            "    *   **Why it's suitable:** The roadmap includes basic model deployment with Flask/FastAPI and cloud platforms. Emphasize this in your resume.  Focus on companies where the role description leans more towards model deployment and less towards heavy-duty software engineering.\n",
            "\n",
            "3.  **Data Science Intern (Convert to FTE):** A Data Science Internship is an excellent way to get your foot in the door. Your goal should be to convert this into a Full-Time Employee (FTE). You'd typically be:\n",
            "    *   Working on specific data science projects under the guidance of experienced data scientists.\n",
            "    *   Learning about different data science techniques and tools.\n",
            "    *   Contributing to real-world data science projects.\n",
            "    *   **Why it's suitable:** Internships are designed for individuals with limited experience to learn and contribute. It provides a low-risk environment for both you and the company to assess your fit.\n",
            "\n",
            "**Open-Source Projects (Suitable for Contribution):**\n",
            "\n",
            "These projects are chosen because they are generally well-documented, have active communities, and offer opportunities to contribute at various levels of skill.\n",
            "\n",
            "1.  **Scikit-learn (Python Machine Learning Library):**\n",
            "    *   **Focus:** A core library for machine learning in Python.\n",
            "    *   **Contribution Opportunities:**\n",
            "        *   **Documentation:** Improving the documentation with clearer explanations, examples, and tutorials is a great way to start.\n",
            "        *   **Bug Fixes:** Identify and fix small bugs in the code.\n",
            "        *   **Testing:** Write unit tests to ensure the library functions correctly.\n",
            "        *   **Feature Implementation:** Contribute to new features or improve existing ones (more advanced, but possible with guidance).\n",
            "    *   **Why it's suitable:** You've used Scikit-learn extensively in the roadmap. Contributing demonstrates your understanding of the library and your ability to collaborate on a larger project.\n",
            "\n",
            "2.  **Pandas (Python Data Analysis Library):**\n",
            "    *   **Focus:** A powerful library for data manipulation and analysis in Python.\n",
            "    *   **Contribution Opportunities:**\n",
            "        *   **Documentation:** Similar to Scikit-learn, documentation improvements are always welcome.\n",
            "        *   **Bug Fixes:** Report and fix bugs in the library.\n",
            "        *   **Performance Optimization:** Identify and optimize slow parts of the code.\n",
            "        *   **New Features:** Contribute to new features that extend Pandas' capabilities.\n",
            "    *   **Why it's suitable:** Pandas is essential for data cleaning and wrangling. Contributing shows your proficiency in data manipulation and your ability to work with complex datasets.\n",
            "\n",
            "3.  **Keras (High-Level Neural Networks API):**\n",
            "    *   **Focus:** A user-friendly API for building and training neural networks (often used as a front-end for TensorFlow or other backends).\n",
            "    *   **Contribution Opportunities:**\n",
            "        *   **Documentation:** Improving the documentation, creating examples, and writing tutorials.\n",
            "        *   **Bug Fixes:** Identifying and fixing bugs.\n",
            "        *   **Adding New Layers or Functions:** Contributing new building blocks for neural networks.\n",
            "        *   **Creating Examples:** Developing new examples that demonstrate how to use Keras for different tasks.\n",
            "    *   **Why it's suitable:** If you chose Deep Learning as your specialization, contributing to Keras is a great way to showcase your knowledge of neural networks and your ability to work with a popular deep learning framework.\n",
            "\n",
            "**Key Strategies for Finding and Securing a Role:**\n",
            "\n",
            "*   **Network, Network, Network:** Attend meetups (in-person or virtual), connect on LinkedIn, and reach out to data scientists in your network for informational interviews.\n",
            "*   **Tailor Your Resume:** Customize your resume for each job application, highlighting the skills and experiences that are most relevant to the specific role.  Quantify your achievements whenever possible (e.g., \"Improved model accuracy by 15%\").\n",
            "*   **Practice Your Interview Skills:** Practice answering common data science interview questions (both technical and behavioral) out loud. Use online resources like LeetCode to practice coding problems.\n",
            "*   **Showcase Your Portfolio:** Make sure your portfolio projects are well-documented, easy to understand, and demonstrate your ability to solve real-world problems.\n",
            "*   **Be Patient and Persistent:** The job search process can be challenging, but don't give up! Keep learning, networking, and applying for jobs, and you will eventually find the right opportunity.\n",
            "\n",
            "Remember to tailor your job search and open-source contributions to your chosen specialization. Good luck!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import MessageGraph, END\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# Node 1: Extract detailed profile\n",
        "def extract_profile(state):\n",
        "    resume_text = state[-1].content\n",
        "    prompt = (\n",
        "        f\"From the following resume, extract these sections separately:\\n\"\n",
        "        f\"1. Skills\\n2. Education\\n3. Experience\\n\\nResume:\\n{resume_text}\"\n",
        "    )\n",
        "    result = model.invoke([HumanMessage(content=prompt)]).content\n",
        "    return state + [AIMessage(content=result)]\n",
        "\n",
        "# Node 2: Generate roadmap\n",
        "def generate_roadmap(state):\n",
        "    extracted_profile = state[-2].content\n",
        "    user_goal = state[-1].content\n",
        "    prompt = (\n",
        "        f\"Use the following profile:\\n{extracted_profile}\\n\\n\"\n",
        "        f\"Now create a realistic 12-month career roadmap to achieve this target:\\n{user_goal}\"\n",
        "    )\n",
        "    roadmap = model.invoke([HumanMessage(content=prompt)]).content\n",
        "    return state + [AIMessage(content=roadmap)]\n",
        "\n",
        "# Node 3: Recommend roles and projects\n",
        "def recommend_jobs_projects(state):\n",
        "    profile = state[-3].content  # AIMessage with extracted profile\n",
        "    goal = state[-1].content     # HumanMessage with goal\n",
        "    prompt = (\n",
        "        f\"Profile:\\n{profile}\\n\\n\"\n",
        "        f\"Career Aspiration:\\n{goal}\\n\\n\"\n",
        "        f\"Suggest 3 suitable job roles and 3 open-source projects that align well.\"\n",
        "    )\n",
        "    output = model.invoke([HumanMessage(content=prompt)]).content\n",
        "    return state + [AIMessage(content=output)]\n",
        "\n",
        "# Build the graph\n",
        "graph = MessageGraph()\n",
        "graph.add_node(\"extract_profile\", extract_profile)\n",
        "graph.add_node(\"generate_roadmap\", generate_roadmap)\n",
        "graph.add_node(\"recommend_jobs_projects\", recommend_jobs_projects)\n",
        "\n",
        "graph.set_entry_point(\"extract_profile\")\n",
        "graph.add_edge(\"extract_profile\", \"generate_roadmap\")\n",
        "graph.add_edge(\"generate_roadmap\", \"recommend_jobs_projects\")\n",
        "graph.add_edge(\"recommend_jobs_projects\", END)\n",
        "\n",
        "agent = graph.compile()\n",
        "\n",
        "# Invoke the graph\n",
        "response = agent.invoke([\n",
        "    HumanMessage(content=\"\"\"\n",
        "    Candidate Resume:\n",
        "    Education: Bachelor of Technology in Computer Science\n",
        "    Skills: Python, LangChain, SQL\n",
        "    Experience: Internship at an AI-based startup\n",
        "    \"\"\"),\n",
        "    HumanMessage(content=\"My goal is to become a Data Scientist within the next year.\")\n",
        "])\n",
        "\n",
        "# Print the final result\n",
        "for msg in response:\n",
        "    print(f\"{msg.type.upper()}:\\n{msg.content}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok  # for tunneling, to access the Streamlit app externally\n",
        "!pip install streamlit pyngrok PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "robGOQMYycYg",
        "outputId": "db8e174a-b1ab-40cf-fdaa-a76498535243"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.48.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.48.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.3.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from pyngrok.exception import PyngrokNgrokHTTPError\n",
        "\n",
        "try:\n",
        "    # Disconnect any existing tunnels\n",
        "    ngrok.kill()\n",
        "    # Connect to the specified port\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(\"Your web app URL:\", public_url)\n",
        "except PyngrokNgrokHTTPError as e:\n",
        "    print(f\"An ngrok error occurred: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hExHdZ2kWgqr",
        "outputId": "0f8c2acd-cd4f-42a0-860c-6e011216edd6"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-08-19T06:35:03+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-08-19T06:35:03+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-08-19T06:35:03+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An unexpected error occurred: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def run_streamlit():\n",
        "    !streamlit run app.py --server.port 8501 --server.enableCORS false\n",
        "\n",
        "# Run Streamlit in the background thread\n",
        "threading.Thread(target=run_streamlit, daemon=True).start()\n",
        "\n",
        "# Wait for Streamlit to start\n",
        "time.sleep(10)\n",
        "\n",
        "# Set ngrok auth token\n",
        "ngrok.set_auth_token(\"30ijUvoQaYp6SRcS11A1rwAuXhQ_37Nn6K7uinS9XXEpzWS7w\")\n",
        "\n",
        "# Open tunnel on port 8501\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(\"App live at:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShJIUiQ9ym9w",
        "outputId": "7b022daa-a3ea-4751-d58a-6aa152c07439"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 06:35:07.284 \n",
            "Warning: the config option 'server.enableCORS=false' is not compatible with\n",
            "'server.enableXsrfProtection=true'.\n",
            "As a result, 'server.enableCORS' is being overridden to 'true'.\n",
            "\n",
            "More information:\n",
            "In order to protect against CSRF attacks, we send a cookie with each request.\n",
            "To do so, we must specify allowable origins, which places a restriction on\n",
            "cross-origin resource sharing.\n",
            "\n",
            "If cross origin resource sharing is required, please disable server.enableXsrfProtection.\n",
            "            \n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "2025-08-19 06:35:07.697 Port 8501 is already in use\n",
            "App live at: NgrokTunnel: \"https://5441035ee33f.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFryl70oA/8QjeJFbssTb7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}